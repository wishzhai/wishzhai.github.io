---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


<p>
  <a href="/docs/CV.pdf" class="btn btn--primary" target="_blank">CV</a>
</p>
<p>
  <a href="/docs/rs.pdf" class="btn btn--primary" target="_blank">Reasearch Statement</a>
</p>


I am currently a Masterâ€™s student in Music at Quanzhou Normal University, supervised by Prof. Jianbin Xiahou, where I participate in the AI-Based Music Generation on Nanyin Music project (Project No. FJ2023JDZ050). My research integrates deep learning with the traditional Nanyin genre, aiming to bridge symbolic representation with the revival of this UNESCO-recognized heterophonic tradition.

Since Nanyin notation captures only the skeletal melody, its essence lies in ornaments and playing techniques. I am therefore particularly interested in expressive MIDI generation and audio synthesis that models playing techniques. Recent contributions include a demo at ISMIR LBD 2025 on expressive MIDI ornament generation, participation in RenCon 2025 for performance rendering, a presentation at HCMIR 2025 discussing improvements to interpolation-based creative music generation systems, and a poster at LLM4Music @ ISMIR 2025 on using large language models to generate audibly challenging music in IDM-like styles.

My long-term goal is to develop human-centered generative AI for music by unifying notation, performance, and timbre. I plan to achieve this by designing interactive interfaces for creative exploration and by leveraging advanced tokenization techniques (e.g., VQ, RVQ). This work aims to empower the generation of nuanced and complex styles, such as free jazz and experimental electronica.
# ğŸ”¥ News
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œWeak Tokenization: A Preliminary Study of Dynamic Audio Chunking for Irregular Music Generation,â€** ISMIR 2025 Workshop LLM4Music.
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œBlaming the Algorithm: An Analysis of Interpolation Failures in MusicVAEâ€™s Latent Space,â€** 3rd Workshop on Human-Centric Music Information Research (HCMIR@ISMIR), 2025.
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ Poster in ICML workshop: New In ML â€” Weixi Zhai, **â€œStory2Nanyin: Chordless, Narrative-Driven Heterophonic Multi-Track MIDI Generation.â€** (paper](https://icml.cc/virtual/2025/50458))
- *2025.06*:&nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œLeveraging PerTok and Domain-Specific Transformer Design for Expressive MIDI Ornament Generation,â€** in *ISMIR 2025 Late-Breaking/Demo*.([Demo](https://pertok-ornament-generation.onrender.com/)) (Initialization may take a few minutes)
- *2025.06*: &nbsp;ğŸ¼ğŸ¼ Participated in the DigiScore CCOM Workshop led by Prof. Ken Fields, watched my favorite synthesizer artist Meng Qiâ€™s new instrumental *Horizon*, and was inspired by everyoneâ€™s novel work on Digital Score Solutions in the context of AI technology. ([Photo](images/digiscore.jpg))
- *2025.03*: &nbsp;âœï¸âœï¸ Honored to participate in the **New-to-ISMIR Mentoring Program 2025** as a mentee, with [Chris Donahue](https://chrisdonahue.com/) as my mentor. I am immensely grateful for his generous support and expertise, which provided me with valuable guidance early in my academic career. The process of preparing a submission under his mentorship was an incredibly formative learning experience.
- *2024.01*: &nbsp;ğŸµğŸµ Joined the online workshop *â€œMarginalized Music Genres and AI Music Generationâ€*, hosted by Prof. Nick Bryan-Kinns, Prof. Qiong Wu, and Prof. Zijin Li. ([Photo](images/marginalizedM.jpg))



# ğŸ“ Publications 

<p>Coming soon...</p>

<!--
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>
-->

# ğŸ“– Educations
- *2023.09 â€“ 2026.06 (expected)*, Master of Arts in Music, Quanzhou Normal University, China  
  Thesis (in progress): Deep Learningâ€“Based Music Generation on Nanyin Musical Features (UNESCO-recognized traditional Chinese music genre)  
  Advisor: Prof. Jianbin Xiahou  

- *2017.09 â€“ 2021.06*, Bachelor of Science in Communication Engineering, China West Normal University, China  


