---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
I am a Masterâ€™s student in Music at Quanzhou Normal University, supervised by Prof. Jianbin Xiahou, participating in the AI-Based Music Generation on Nanyin Music project (Project No. FJ2023JDZ050). My research combines deep learning with the traditional Nanyin genre, aiming to bridge symbolic representation and the revival of this UNESCO-recognized heterophonic musical tradition.

Since Nanyin notation captures only the skeletal melody, its essence lies in ornaments and playing techniques. I am therefore particularly interested in expressive MIDI generation and audio synthesis that models playing techniques. Recent contributions include a demo at ISMIR LBD 2025 on expressive MIDI ornament generation, participation in RenCon 2025 for performance rendering, a presentation at HCMIR 2025 discussing improvements to interpolation-based creative music generation systems, and a poster at LLM4Music @ ISMIR 2025 on using large language models to generate audibly challenging music in IDM-like styles.

My ongoing research explores cutting-edge tokenization techniques such as Vector Quantization, Residual VQ, and Finite Scalar Quantization, with potential applications extending from free jazz to chopped breakbeats and experimental works by artists like Burnt Friedman. My long-term goal is to develop human-centered generative AI that unifies notation, performance, and timbre to enable creativity-driven music and audio generation.

# ğŸ”¥ News
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œWeak Tokenization: A Preliminary Study of Dynamic Audio Chunking for Irregular Music Generation,â€** ISMIR 2025 Workshop LLM4Music.
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œBlaming the Algorithm: An Analysis of Interpolation Failures in MusicVAEâ€™s Latent Space,â€** 3rd Workshop on Human-Centric Music Information Research (HCMIR@ISMIR), 2025.
- *2025.06*:&nbsp;ğŸ‰ğŸ‰ Paper accepted: Weixi Zhai, **â€œLeveraging PerTok and Domain-Specific Transformer Design for Expressive MIDI Ornament Generation,â€** in *ISMIR 2025 Late-Breaking/Demo*.
- *2025.06*: &nbsp;ğŸ¼ğŸ¼ Participated in the DigiScore CCOM Workshop led by Prof. Ken Fields, watched my favorite synthesizer artist Meng Qiâ€™s new instrumental *Horizon*, and was inspired by everyoneâ€™s novel work on Digital Score Solutions in the context of AI technology.
- *2025.03*: &nbsp;ğŸ–ŠğŸ–Š Honored to participate in the **New-to-ISMIR Mentoring Program 2025** as a mentee, with [Chris Donahue](https://chrisdonahue.com/) as my mentor. Although my paper was ultimately not accepted, the experience provided me with invaluable learning opportunities and insights into the research process.
- *2024.01*: &nbsp;ğŸµğŸµ Joined the online workshop *â€œMarginalized Music Genres and AI Music Generationâ€*, hosted by Prof. Nick Bryan-Kinns, Prof. Qiong Wu, and Prof. Zijin Li.


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**



# ğŸ“– Educations
- *2023.09 â€“ 2026.06 (expected)*, Master of Arts in Music, Quanzhou Normal University, China  
  Thesis (in progress): Deep Learningâ€“Based Music Generation on Nanyin Musical Features (UNESCO-recognized traditional Chinese music genre)  
  Advisor: Prof. Jianbin Xiahou  

- *2017.09 â€“ 2021.06*, Bachelor of Science in Communication Engineering, China West Normal University, China  


